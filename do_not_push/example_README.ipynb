{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f6d659",
   "metadata": {},
   "source": [
    "# Disaster Response Pipeline and Web App\n",
    "- [Project Overview](#Project-Overview)\n",
    "- [Installation](#Installation)\n",
    "- [Project Components](#Components)\n",
    "- [File Descriptions](#File-Descriptions)\n",
    "- [Instructions](#How-To-Run-This-Project)\n",
    "- [Discussion](#Discussion)\n",
    "- [Licensing, Authors, Acknowledgements](#License)\n",
    "\n",
    "## Project Overview <a name=\"Project-Overview\"></a>\n",
    "The Disaster Response Pipeline project is part of the Udacity Data Science Nano Degree in collaboration with Figure Eight. This project builds a Natural Language Processing (NLP) pipeline classifying disaster messages into several categories. The project also provides a web application that lets an emergency worker, in case of disaster events, inputs new messages, get classification results, then send the messages to appropriate disaster relief agencies.  \n",
    "\n",
    "**Background:** Figure Eight provided a pre-labeled dataset containing tweets and messages sent in real-life disaster events. These real messages are labeled with categories such as water, food, medical help, shelter, and so on. Following a disaster, there are millions of messages received either directly or via social media. Often time the disaster response organizations have the least capacity to filter the messages when a disaster is happening. Therefore, supervised machine learning models categorizing the messages based on keywords with high accuracy is desirable in order to investigate new trends and help Figure Eight respond to future disaster messages.\n",
    "\n",
    "\n",
    "**The goal** of this project is to build an NLP pipeline that processes the text data and performs multi-output classification on 36 categories. GridSearchCV is also implemented to tune the best parameters for the model. Finally, a web app built from Flask will display some visualization about data, take in new messages and classify their categories. Details on the dataset and machine learning model choice are discussed below.\n",
    "\n",
    "## Installation <a name=\"Installation\"></a>\n",
    "The following packages and versions are used in this jupyter notebook. Any recent versions should work.\n",
    "| Package  | Version |\n",
    "| ------------- | ------------- |\n",
    "| Python  | 3.8.5  |\n",
    "| Pandas  | 1.1.3  |\n",
    "| Numpy   | 1.19.2 |\n",
    "| Matplotlib | 3.3.2|\n",
    "| sqlalchemy | 2.5.1|\n",
    "| nltk    | 3.6.2|\n",
    "| scikit-learn  | 0.24.2|\n",
    "| pickle  | 1.6.0|\n",
    "| Flask   | 1.1.2|\n",
    "| json    | 0.9.6|\n",
    "| plotly  | 4.4.13|\n",
    "| joblib  | 1.0.1|\n",
    "\n",
    "## Project Components <a name=\"Components\"></a>\n",
    "There are 3 main components in this project.\n",
    "### 1. ETL pipeline\n",
    "- Load two datasets\n",
    "- Merge the sets and clean the data\n",
    "- Store the data in a SQLite database\n",
    "\n",
    "### 2. ML pipeline\n",
    "- Load the clean data from the SQLite database\n",
    "- Split the data to train-test sets\n",
    "- Build a text processing and machine learning model with NLTK\n",
    "- Train and tune the model with GridSearchCV\n",
    "- Evaluate the model\n",
    "- Export the final model as a pickle file\n",
    "\n",
    "### 3. Flask Web App\n",
    "A web application displays some visualization about the dataset. Users can type in any new messages in the web app and receive the categories that the message may belong to.\n",
    "\n",
    "![input](img/input.JPG)\n",
    "Figure 1. Input field takes in new messages.\n",
    "\n",
    "![genre dist](img/genre.png)\n",
    "Figure 2. The distribution of message genres provided by the dataset.\n",
    "\n",
    "![cat dist](img/cat_dist.png)\n",
    "Figure 3. Pre-labelled messages categories.\n",
    "\n",
    "![top 10](img/top10.png)\n",
    "Figure 4. Distribution of messages by genres in top 10 categories.\n",
    "\n",
    "![example](img/example.JPG)\n",
    "Figure 5. An example message _\"We are more than 50 people sleeping on the street. Please help us find' tent, food.\"_ is classified in the following categories: request, offer, medical help, shelter, clothing.\n",
    "\n",
    "## File Description <a name=\"File-Descriptions\"></a>\n",
    "This is the high level description of all the files in this project.\n",
    "```\n",
    "├── app\n",
    "│   ├── run.py--------------------------------# Flask file runs the web app\n",
    "│   └── templates\n",
    "│       ├── go.html---------------------------# Result page\n",
    "│       └── master.html-----------------------# Main page\n",
    "├── data\n",
    "│   ├── DisasterResponse.db-------------------# *Database storing the processed data\n",
    "│   ├── disaster_categories.csv---------------# Pre-labelled dataset\n",
    "│   ├── disaster_messages.csv-----------------# Data\n",
    "│   ├── process_data.py-----------------------# ETL pipeline processing the data\n",
    "|   └── ETL Pipeline Preparation_NP.ipynb-----# Jupyter notebook with details\n",
    "├── img---------------------------------------# Visualizations captured from the web app\n",
    "├── models\n",
    "|   ├── train_classifier.py-------------------# Machine learning pipeline\n",
    "│   ├── ML Pipeline Preparation_NP.ipynb------# Jupyter notebook with details\n",
    "|   └── classifier.pkl------------------------# *Pickle file\n",
    "\n",
    "*Files that will be generated when the python scripts .py are executed.\n",
    "```\n",
    "\n",
    "The original datasets are provided in `.csv` files <br>\n",
    "2 jupyter notebooks `.ipynb` detail the data cleaning and machine learning processes. <br>\n",
    "A README.md file describes this repository.\n",
    "\n",
    "## Instructions <a name=\"How-To-Run-This-Project\"></a>\n",
    "### 1. Download the files or clone this repository\n",
    "  ```\n",
    "  git clone https://github.com/Az-otrope/Disaster-Response-ML-and-Web-App\n",
    "  ```\n",
    "### 2. Execute the scripts\n",
    "a. Open a terminal <br>\n",
    "b. Direct to the project's root directory <br>\n",
    "c. Run the following commands: <br>\n",
    "- To run ETL pipeline that cleans data and stores in database\n",
    "  ```\n",
    "  python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db\n",
    "  ```\n",
    "- To run ML pipeline that trains classifier and saves\n",
    "  ```\n",
    "  python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl\n",
    "  ```\n",
    "\n",
    "d. Go to the app's directory and run the command\n",
    "```sh\n",
    "cd app\n",
    "python run.py\n",
    "```\n",
    "![result](img/result.JPG)\n",
    "\n",
    "e. The web app instantiates. Type http://0.0.0.0:3001/ or http://localhost:3001/ to launch the webpage on the web browser.\n",
    "\n",
    "![run](img/run.JPG)\n",
    "\n",
    "f. Input any message in the input box and click on the Classify Message button to see the categories that the message may belong to.\n",
    "\n",
    "## Discussion <a name=\"Discussion\"></a>\n",
    "### 1. Dataset distribution\n",
    "According to figures 3 and 4, this dataset is highly imbalanced. We can see that most messages are classified in the top 10 categories: related, aid-related, weather-related, request, and so on. Given this pre-labeled dataset, most newly entered disaster messages will be classified as _related_ which doesn't give much useful information.\n",
    "\n",
    "In some cases, the message contains words that don't directly point to any particular category but its implication is still important. For instance, a message saying _\"The water pipes break and my house floor is covered in water\"_. The model catches the key words and classifies this message into _water, aid help_ categories, but instead the _flood, building, infrastructure_ maybe more accurate. This signals that the context is an important factor to properly label messages' categories.\n",
    "\n",
    "### 2. ML model choice\n",
    "One of the goals of this project is to implement the use of GridSearchCV to tune and find the best parameters for the model. However, the final model chosen for this project is a Random Forest Classification without tuned parameters, since it produces the highest accuracy.\n",
    "\n",
    "The jupyter notebook `ML Pipeline Preparation_NP` entails two other classification models, KNN and Decision Tree. Three algorithms are tested with and without GridSearchCV. They are then scored against each other based on the accuracy scores. All models performed better without GirdSearch implementation. This could be due to the highly imbalanced data and poor labels.\n",
    "\n",
    "### 3. Suggestions\n",
    "The following suggestions can improve the model: <br>\n",
    "a. f1-score is better as a comparison metric for imbalanced dataset <br>\n",
    "b. Take the context of the message into account to improve the labelling process for training data.\n",
    "\n",
    "\n",
    "## Licensing, Authors, Acknowledgements <a name=\"License\"></a>\n",
    "* [Figure Eight](https://www.figure-eight.com/) for providing the datasets and directions\n",
    "* [Udacity](https://www.udacity.com/) for project goal\n",
    "* Author: [Nguyen Pham](https://github.com/Az-otrope)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
